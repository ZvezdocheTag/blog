---
title: Modal Interfaces
date: 2019-08-23
---

As a former interaction designer, I like to think about the history of user interface design from time to time.
I'm certainly biased by the technology I'm exposed to, but I can't help but wonder what modern UI would look like
if the industry hadn't wholesale rejected the idea of modal interfaces in the 80s and 90s.
I'm an avid Vim user, which is notorious for its modal interface that often leaves new users confused and unable to quit the program.
Vim's interface has remained largely the same for 30 years. I would argue that it's difficult to find ways to improve upon the interface, mostly because there hasn't been much modal-based interface design exploration in the time since it was released, not because it couldn't be better.
The thing about modal interfaces, like command line interfaces, is that they're not designed to be quick to learn, they are designed to be efficient.
Many studies have shown how command line interfaces are vastly more efficient than their GUI counterparts, but they tend to come with a steeper learning curve.
I think both approaches have their places, but when I think about how much professional-grade software is
hindered by the limitations in GUI-based software, I can't help but think we're missing a huge opportunity for professional workers.

I recently received a Teenage Engineering OP-Z as a gift, and it's gotten me thinking about modality in interface design again.
Like a lot of electronic music hardware, the OP-Z's interface is based around modes.
The OP-Z's hardware includes several rows of LED-lit buttons with numbers and cryptic icons and four rotary dials in lieu of a screen and cursor.
You hold one key to switch between tracks, another to switch between projects, another to change the tempo settings, and a combination of keys to enter *sample mode*.
It takes a little bit of reading, watching YouTube videos, and fiddling around with to get the hang of, but I was actually surprised by how well designed the interface was and how quickly I was able to make sounds that resembled music.

While the device can run completely on its own,
it does include an optional iOS app that displays richer information about the current mode you're in and includes visual feedback for editing sounds, but the app really is only intended as a display and most interactions are handled on the device itself.
It sort of turns the device into a music-making laptop of sorts.
It's also an excellent example of a modern modal interface designed for efficiency in music performance.

One of the biggest appeals to me about the OP-Z was its modal interface.
I've been using Ableton Live for nearly 16 years, and I've certainly built up some muscle memory for keyboard shortcuts, but the interface is still very GUI-driven, and it takes time to move a mouse around to perform certain actions.
The interface is partially modal, and Ableton now has its own dedicated Push hardware, that is also modal-based, but the overall interface of Ableton wasn't designed from the ground-up with this in mind.

The biggest problem in modal interfaces is what's known as *mode errors*.
Because the same keys or buttons can produce different results based on the current mode,
mode errors occur when the user believes they are in a different mode and performs actions intended for that other mode.
If you've ever started typing text not realizing that the caps lock key was engaged, you've made a mode error.
Mode errors are real, and they certainly happen,
but I believe there are likely many unexplored solutions for this problem.
With technology like predictive typing and autosuggest, I'd imagine we could write programs that warn when actions appear to be orthogonal to the current mode.






